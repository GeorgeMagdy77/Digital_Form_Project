# Default helm values for n8n.
# Default values within the n8n application can be found under https://github.com/n8n-io/n8n/blob/master/packages/cli/src/config/index.ts
n8n:
  # if not specified n8n on first launch creates a random encryption key for encrypting saved credentials and saves it in the ~/.n8n folder
  encryption_key:
defaults:

config:
  executions:
    # prune executions by default
    pruneData: "true"
    # Per default, we store 1 year of history
    pruneDataMaxAge: 3760
  database:
   type: postgresdb
   postgresdb:
     database:       n8n
     host:           postgres
     port:           5432
     user:           postgres

# Set additional environment variables on the Deployment
extraEnv:
  QUEUE_BULL_REDIS_HOST: n8n-redis-master
  N8N_BLOCK_ENV_ACCESS_IN_NODE: true
  NODES_EXCLUDE: '["n8n-nodes-base.executeCommand"]'

# Set this if running behind a reverse proxy and the external port is different from the port n8n runs on
#   WEBHOOK_URL: "https://n8n.myhost.com/

# Set additional environment from existing secrets
extraEnvSecrets:
# for example, to reuse existing postgres authentication secrets:
  N8N_ENCRYPTION_KEY: 
    name: encryption-key
    key: N8N_ENCRYPTION_KEY
  DB_POSTGRESDB_PASSWORD:
    name: postgres-password
    key: POSTGRES_PASSWORD
  QUEUE_BULL_REDIS_PASSWORD:
    name: redis-password
    key: REDIS_PASSWORD

## Common Kubernetes Config Settings
persistence:
  ## If true, use a Persistent Volume Claim, If false, use emptyDir
  ##
  enabled: false
  # what type volume, possible options are [existing, emptyDir, dynamic] dynamic for Dynamic Volume Provisioning, existing for using an existing Claim
  type: existing
  ## Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: ""
  ## PVC annotations
  #
  # If you need this annotation include it under values.yml file and pvc.yml template will add it.
  # This is not maintained at Helm v3 anymore.
  # https://github.com/8gears/n8n-helm-chart/issues/8
  #
  # annotations:
  #   volume.beta.kubernetes.io/storage-provisioner: csi.vsphere.vmware.com
  #   volume.kubernetes.io/storage-provisioner: csi.vsphere.vmware.com

  ## Persistent Volume Access Mode
  ##
  # accessModes:
  #   - ReadWriteOnce
  ## Persistent Volume size
  ##
  # size: 10Gi
  ## Use an existing PVC
  ##
  existingClaim: n8n-pvc

replicaCount: 3

# here you can specify the deployment strategy as Recreate or RollingUpdate with optional maxSurge and maxUnavailable
# If theses options are not set, default values are 25%
# deploymentStrategy:
#  type: RollingUpdate
#  maxSurge: "50%"
#  maxUnavailable: "50%"

deploymentStrategy:
  type: "RollingUpdate"

image:
  repository: n8nio/n8n
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podLabels: {}

podSecurityContext: {}
  # runAsNonRoot: true
  # runAsUser: 1001200001
  # runAsGroup: 1001200001
  # fsGroup: 1001200001

securityContext: {}
 # capabilities:
  #   drop:
#   - ALL
# readOnlyRootFilesystem: true
# runAsNonRoot: true
# runAsUser: 1000
   # runAsUser: 1001200001
   # allowPrivilegeEscalation: false
   # capabilities:
   #   drop:
   #   - ALL
   # seccompProfile:
   #   type: RuntimeDefault
   #
# here you can specify lifecycle hooks - it can be used e.g to easily add packages to the container without building
# your own docker image
# see https://github.com/8gears/n8n-helm-chart/pull/30
lifecycle:
  {}

#  here's the sample configuration to add mysql-client to the container
# lifecycle:
#  postStart:
#    exec:
#      command: ["/bin/sh", "-c", "apk add mysql-client"]

# here you can override a command for main container
# it may be used to override starting script (e.g. to resolve issues like https://github.com/n8n-io/n8n/issues/6412) or
# run additional preparation steps (e.g. installing additional software)
command: []

# sample configuration that overrides starting script and solves above issue (also it runs n8n as root, so be careful):
# command:
#  - tini
#  - --
#  - /bin/sh
#  - -c
#  - chmod o+rx /root; chown -R node /root/.n8n || true; chown -R node /root/.n8n; ln -s /root/.n8n /home/node; chown -R node /home/node || true; node /usr/local/bin/n8n

# here you can override the livenessProbe for the main container
# it may be used to increase the timeout for the livenessProbe (e.g. to resolve issues like

livenessProbe:
  httpGet:
    path: /healthz
    port: http
  # initialDelaySeconds: 30
  # periodSeconds: 10
  # timeoutSeconds: 5
  # failureThreshold: 6
  # successThreshold: 1

# here you can override the readinessProbe for the main container
# it may be used to increase the timeout for the readinessProbe (e.g. to resolve issues like

readinessProbe:
  httpGet:
    path: /healthz
    port: http
  # initialDelaySeconds: 30
  # periodSeconds: 10
  # timeoutSeconds: 5
  # failureThreshold: 6
  # successThreshold: 1

# here you can add init containers to the various deployments
initContainers: []

service:
  type: ClusterIP
  port: 5678
  annotations: {}

ingress:
  enabled: false
  annotations: {}
  # kubernetes.io/ingress.class: nginx
  # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths: []
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

  # define a custom incressClassName, like "traefik" or "nginx"
  className: ""

workerResources:
  limits:
    cpu: 1000m
    memory: 1024Mi
  requests:
    cpu: 200m
    memory: 256Mi


webhookResources:
  {}

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  limits:
    cpu: 1000m
    memory: 1024Mi
  requests:
    cpu: 200m
    memory: 256Mi

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 6
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

scaling:
  enabled: true

  worker:
    count: 3
    concurrency: 3
  # With .Values.scaling.webhook.enabled=true you disable Webhooks from the main process but you enable the processing on a different Webhook instance.
  # See https://github.com/8gears/n8n-helm-chart/issues/39#issuecomment-1579991754 for the full explanation.
  webhook:
    enabled: false
    count: 1

## Bitnami Redis configuration
## https://github.com/bitnami/charts/tree/master/bitnami/redis
redis:
  enabled: true
  architecture: replication
  auth:
    enabled: true
    existingSecret: redis-password
    existingSecretPasswordKey: REDIS_PASSWORD
